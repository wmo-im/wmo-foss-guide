=== WMO Activities

==== Coordination, alignment and support (TODO Dave/Enrico)

[Note]
====
* Coordination/support functions
* Software selection for WMO projects and application development
* Managing FOSS activities
* Aligning with WMO ecosystem of activities
* Ensuring sustainability of FOSS usage
* Managing risk
* Functions
* People
====

As FOSS has become increasinlgy embedded in WMO programmes, projects and Member operations, the need for structured
coordination at the organisational level has grown accordingly. Historically, software developed, or selected, for use
in different projects and programmes has largely been managed on an ad-hoc basis. Independent experts, contractors,
and implementaing authorities / agencies have typically made independent choices without a common framework for the
evaluation, governance or lifecylce management of FOSS. Whilst enabling rapid development and innovation, this
approach has led to fragmentation and duplication of effort, and in some cases, reliance on unmaintained or insecure
software that puts Members services at risk.

The WMO Secretariat, as the body supporting the work of the constituent bodies, has a central role in coordinating
FOSS activities across WMO programmes and projects and is supporting Members in the FOSS adoption. This coordination
function should ensure that FOSS initiatives are aligned with the WMO's regulatory framework and that software used
in support of WMO obligations meets appropriate standards of quality and security. Equally important, this coordination
should ensure that Members, particularly those with limited technical capacity, are not left behind.

===== Governance and organisational functions

Effective FOSS coordination with the WMO requires dedicated governance functions. The following functions are identified
as essential:

* **Software evaluation and review**: Providing a consistent process for assessing FOSS used in WMO programmes and
projects, applying criteria such as those described in the FOSS evaluation rubric (see <<annex-evaluation-rubric>>).
This includes evaluating license compatibility, security posture, project and community health, openness of governance,
and technical fitness for purpose.
* **Lifecycle oversight**: Tracking the status of FOSS components used across WMO programmes, from initial adoption
through operational use to end-of-life, ensuring that migration plans are in place when software is no longer maintained.
* **Standards alignment**: Ensuring that FOSS developed or endorsed within WMO implements relevant Technical Regulations
and open standards correctly and consistently.
* **Guidance and advisory support**: Providing practical guidance to Expert Teams, Task Teams, Communities of
Practice, and other implementors on FOSS best practices, including licensing, contribution workflows, governance models
and release management.

These functions may be carried out by existing WMO bodies, such as the Standing Committees, Expert Teams, and Task Teams.
However, these bodies often have a narrow focus on a particular activity or area, are not typically involved involved in
the projects implementing or using FOSS, and ofetn and lack the specialist knowledge on FOSS. Alternatively, a dedicated
software review function, such as through an Open Source Program Office (OSPO), could be established. Regardless of the
organisational form, there is a clear requirement for software governance to be systematic rather than ad-hoc, and that
clear, objective criteria exist for evaluating and endorsing FOSS within WMO.

It is important to note that WMO should not seek to develop its own registry of open-source software.
Existing registries and ecosystems (such as those maintained by OSGeo, the Digital Public Goods Alliance, and
language-specific package repositories) already serve this purpose.  WMO's coordination role should focus on evaluating
and recommending software from within these existing ecosystems, rather than duplicating their efforts.

===== Roles and responsibilities

Coordination of FOSS activities within the WMO involves range of actors:

* **WMO Secretariat**: Facilitates coordination across programmes and projects, supports the development and maintenance
of FOSS guidance, and manages relationships with external FOSS organizations.  The Secretariat also provides continuity
and institutional memory for FOSS initiatives that span multiple Commission sessions.
* **Expert Teams and Task Teams**: Provide domain-specific expertise in evaluating and developing FOSS relevant to their
areas of responsibility.  Expert Teams and Task Teams may identify candidate software for endorsement or develop Reference
Implementations of WMO standards.
* **Communities of Practice**: Serve as collaborative spaces where Members, developers and stakeholders work together on
shared FOSS initiatives.  Communities of Practice can play an important role in maintaining and evolving software that
supports WMO standards, as demonstrated by the development of Reference Implementations within the WIS2 programme and
the OpenCDMS project and initiative.
* **Members**: Contribute expertise, code, testing and operational feedback.  Members with mature FOSS programmes can
serve as mentors and collaborators for those building capacity.

Whilst "Communities of Practice" have been listed above, these do not exsit formally within the WMOs framework and
constituent bodies, instead operating on an informal basis. Strengthening and formally recognising these communities
would have significant benefit.

===== FOSS project life cycle

===== FOSS sustainability and risk management

===== Alignment with the WMO ecosystem

===== Supporting Members

===== External partnerships

[Note]
====
DB: This text has been cut from above and left here so it is not forgotten. If no home is found later
it can be deleted.

Examples include software such as the WIS2box, developed as a reference implementation of a WIS2.0 node, and
the ClimWeb software, developed to give Members a web and social media presence for communicating with key stakeholders.
====


==== Standards compliance

FOSS can also play a significant role as an indicator of the feasibility of Technical Regulation
implementation.  As part of the standards development phase, developing the associated FOSS
implementation(s) aids in determining "fit for purpose" of the specification.  In addition, FOSS
implementation during standards development allows for an open review and assessment on how a
standard is implemented (supported network protocols, avaiability of tooling/libraries for
integration, as well as speed of implementation (if a FOSS implementation during the development
of a standard takes a considerable level of effort, why?  Is the complexity acceptable for the
scope of the standard?  Determining these aspects earlier can help improve and adjust the standard
while in development (as opposed to formal amendment processes once approved by WMO).  The agile and parallel
development of WIS2 standards and FOSS is a key example in this context (see <<_case_study_wis2_foss_and_agile_development>>).

Another indicator is the number of implementations.  For example, the Open Geospatial Consortium (OGC)
mandates that a proposed standard requires at least 3 implementations for consideration by its
Technical Committee.  This provides "proof" to the Technical Committee that the standard can be
implemented, and has investment from various projects as early adopters.

In summary, while FOSS is not in scope for being identified as part of a Technical Regulation, it
is a strong indicator of the the maturity, applicability and sustainability of a given standard.  Implementing
FOSS during standards development provides safety in investment, iterative improvements,
and confidence for widespread and sustainable adoption and implementation by Members.

==== Software review and evaluation

The identification and selection of software for WMO-related activities and Member implementations should follow a structured, transparent and repeatable assessment process. This applies equally to FOSS and proprietary solutions and aims to reduce technical, operational and organizational risks while increasing confidence in long-term sustainability, interoperability and compliance with WMO frameworks.
Before adopting, recommending or endorsing a software solution, Members and WMO bodies are encouraged to perform a lightweight but systematic project assessment covering at least the following dimensions:

* Purpose and scope alignment. The software should have a clearly defined purpose and scope, aligned with the intended operational, research or regulatory use case. Its role within the overall system architecture (e.g. data production, exchange, discovery, processing or visualization) should be explicit and overlaps or dependencies with existing solutions should be identified.
* Standards and regulatory compliance. The software should demonstrably support relevant WMO Technical Regulations, standards and recommended practices, as applicable (e.g. WIS2, BUFR, GRIB, NetCDF, WMO Core Metadata Profile). Where full compliance is not yet achieved, gaps, limitations and mitigation measures should be clearly documented.
* Licensing and policy compatibility. Licensing terms must be clearly stated and compatible with national regulations, WMO data policies and operational constraints. For FOSS, licenses should be OSI-approved and allow redistribution, modification and operational use without legal ambiguity.
* Project maturity and sustainability. The assessment should consider the maturity of the project, including release history, roadmap availability, versioning practices and evidence of operational use. Indicators such as the number of active contributors, governance transparency, institutional backing and the “bus factor” provide insight into long-term sustainability and associated risks.
* Security and risk management. The project should have documented security practices, including vulnerability reporting mechanisms, patching policies and incident response procedures. Known risks, external dependencies and lifecycle considerations (including end-of-life or migration paths) should be evaluated early in the selection process.
* Technical quality and operational fitness. Software quality should be assessed based on documentation availability, test coverage, automation (e.g. CI/CD), performance at NMHS-relevant data volumes, and ease of deployment, operation and maintenance. Evidence of production use within the WMO community or by peer organizations is a strong positive indicator.
* Organizational readiness and total cost of ownership (TCO). Adopting organizations should evaluate internal capacity, including staff skills, support models, infrastructure requirements and TCO. This includes training needs, long-term maintenance effort and the ability to contribute fixes or enhancements upstream where appropriate.

To support early-stage identification and comparison, Members and WMO activities may also consult community-maintained software catalogues, such as the FOSS4G Observatory (https://project.oss4geo.org/). These platforms provide structured metadata for a wide range of open-source software projects, including functional scope, licensing, governance characteristics, development activity and dependency relationships. Such catalogues can assist with preliminary screening and ecosystem-level understanding, but the information they provide should be treated as indicative and complementary.

For consistency and transparency, WMO encourages the use of a common evaluation checklist or rubric, such as the one provided in <<annex-evaluation-rubric, Annex A>>, and promotes rolling reviews of selected software to account for evolving requirements, standards and ecosystem changes. This assessment process does not seek to formally “approve” specific software for inclusion in WMO Technical Regulations, but rather to provide confidence-based guidance and shared criteria to support informed decision-making and harmonized adoption across the WMO ecosystem. 

* "Approved projects" and/or Reference Implementations
** Make Tech Regs more concrete
** Tech Regs -> FOSS implementations
** Should FOSS be cited in WMO Tech Regs (suggest no)
** Rolling review
* Harmonization: regular review of ecosystem to ensure alignment and optimal use of resources

===== Compliance (data exchange)

* **Standards alignment**: The software adheres to WMO technical standards and common industry specifications, unifying
data exchange interfaces and formats.
* **Data protection**: It complies with international conventions and national data protection regulations by
implementing data desensitization, encrypted data transmission, and secure storage of sensitive meteorological data.
* **Cross-border data security**: It meets data cross-border transfer requirements in operational regions by establishing
a full lifecycle data-security management mechanism. This mechanism covers data collection, processing, sharing, and
archiving in line with WMO data policies.

===== Software evaluation

* **Core Evaluation Checklist**:
** __Technical Quality__: Functionality completeness and accuracy for meteorological use cases, performance when
processing massive meteorological datasets (e.g., real-time observational data, forecast model outputs), reliability
under peak load conditions, security, maintainability, and compatibility with existing meteorological systems.
** __Compliance__: License is OSI-approved with no license conflicts, and complies with WMO data policies and relevant regulations.
** __Community Sustainability__: Recent community activity (within the last 6–12 months), stability of the maintenance
team, regularity of version releases, and maturity of the ecosystem.
** __Cost-effectiveness__: Controllable costs across the software lifecycle (deployment, operation, maintenance, training,
migration, and decommissioning).
** __Business Fit__: Aligns with existing meteorological operational processes, good usability for forecasters and data
analysts, and support for future expansion needs.

* **Confidence Assurance:**

** Adopt standardized evaluation processes and quantifiable metrics to ensure objectivity and repeatability of results.
** Validate core functionality through a Proof-of-Concept (PoC) approach, incorporating feedback collected from real-world operational scenarios.
** Conduct multi-dimensional verification, including code audits, security vulnerability scans, and in-depth open source community research, to confirm the reliability of the software.

===== Readiness

Completed drafting of requirements specification documents, and form a professional evaluation team (including technical, business, legal, and operations personnel).

Set up a simulated meteorological operations testing environment, and prepare test data (including extreme weather scenario data) and necessary evaluation tools.

Define clear priorities for software requirements and establish final decision criteria, such as approval for full adoption, conditional adoption, or rejection. Document the rationale for all decisions for audit purposes.

===== Bus/retirement factor

===== Business Fit and Retirement Considerations

* Business Fit

** Offers seamless integration with existing meteorological operational processes, minimizing the need for process adjustments.
** Supports custom development and feature expansion to meet evolving needs (such as business scaling and new scenario integration).
** Aligns with users’ habits in meteorological operations by providing a user-friendly interface and flexible configuration options.

* Retirement Planning

** Establish a clear data archiving plan to ensure secure storage and traceability of historical meteorological data after the software is decommissioned.
** Proactively assess the costs of migrating to new systems, and establish a smooth migration path to ensure business continuity.
** Define clear responsibilities and standardized procedures for software retirement to mitigate potential risks (e.g., data leakage, system conflicts, and service disruptions).

==== Case study: WIS2, FOSS, and agile development

The WMO Information System 2.0 (WIS 2.0) is the framework for WMO data sharing in the 21st century for all WMO domains and disciplines. It supports the WMO Unified Data policy and the Global Basic Observing Network (GBON) and makes international, regional, and national data sharing simple, effective, and inexpensive. The idea that no Member should be left behind and the objective of lowering the barrier to adoption has been at the core of WIS 2.0 development. These objectives inspire the principles underpinning the WIS 2.0 technical framework, such as adopting open standards and Web technologies to facilitate sharing of increasing variety and volume of real-time data.footnote:[https://wmo.int/wis-20]

The WMO Executive Council, through https://library.wmo.int/idviewer/66258/1147[Resolution 34 (EC-76)] - Implementation plan update of the WMO Information System 2.0, endorsed the WMO Information System 2.0 (WIS2) implementation plan. The Resolution also recognized the importance of establishing a pilot phase to develop the WIS2 infrastructure and begin testing it, in order to be ready for a pre-operational phase in 2024, and then for the transition starting in 2025.

The pilot phase was completed at the end of 2023, with several Members collaborating in building the WIS2 infrastructure. Each Member had a different role in the WIS2 framework and implemented a specific component. Starting in January 2024, the implementation of WIS2 entered the pre-operational phase in preparation for transitioning to WIS2.  On 01 January 2025, WIS2 became operational.footnote:[https://wmo-im.github.io/wis2-transition-guide/transition-guide/wis2-transition-guide-APPROVED.html#_1_introduction]

WIS2 is comprised of a number of key standards, including (but are not limited to):

* Internet and messaging protocols for data and metadata transmission (HTTP, MQTT)
* metadata encodings for dataset descriptions (WMO Core Metadata Profile) and notifications (WIS2 Notification Message)
* topic structures for real-time notifications (WIS2 Topic Hierarchy)
* interfaces and APIs for Global Services (Global Discovery Catalogue)

Throughout the WIS2 Implementation timeline, the https://raw.githubusercontent.com/wmo-im/wis2-guide/refs/heads/main/guide/images/architecture/c4.container.png[architecture], standards definitions as well as key software components were developed, deployed and tested in parallel, in an agile manner.  These software include (but are not limited to):

[cols="1,1"]
|===
|Software|WIS2 component(s)

|https://docs.wis2box.wis.wmo.int[wis2box]
|WIS2 Node
 
|https://github.com/wmo-im/wis2-gdc[wis2-gdc]
|Global Discovery Catalogue
 
|https://github.com/World-Meteorological-Organization/csv2bufr[csv2bufr]
|CSV to BUFR encoding tool for station data
 
|https://github.com/World-Meteorological-Organization/wis2downloader[wis2downloader]
|Python package for downloading real-time data from WIS2
 
|https://github.com/World-Meteorological-Organization/pywis-pubsub[pywis-pubsub]
|Python package providing notification message publishing, subscription and data download capability in WIS2

|===

Driven by collaboration, the development and testing of FOSS significantly helped with early assessment of the WIS2 standards in development.  As a result, WIS2 standards were being tested in an agile environment and rapid feedback was provided that helped refine, adjust and improve the standards early and often.

WIS2 FOSS implementations have resulted in a more stable and robust program delivery with significantly reduced risk to Members.  In addition, some tools have emerged as "Reference Implementations" as key resources for the precise implementation of various WIS2 standards which can either be deployed or studied by Members accordingly.  WIS2 Technical Regulations were approved with confidence as a result of the agile development of Open Standards and Open Source.
